name: CI Pipeline

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master, develop ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11']
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install flake8 pytest pytest-cov black mypy
    
    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=120 --statistics
    
    - name: Format check with black
      run: |
        black --check --diff .
      continue-on-error: true
    
    - name: Type check with mypy
      run: |
        mypy . --ignore-missing-imports
      continue-on-error: true
    
    - name: Run tests
      run: |
        pytest -v --cov=. --cov-report=xml --cov-report=html
      continue-on-error: true
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      if: matrix.python-version == '3.10'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  quality-check:
    runs-on: ubuntu-latest
    needs: lint-and-test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run quality validation
      run: |
        python qa/validation_system.py --run-all
    
    - name: Generate quality report
      run: |
        python qa/quality_scorer.py --generate-report
    
    - name: Upload quality reports
      uses: actions/upload-artifact@v3
      with:
        name: quality-reports
        path: qa_reports/

  data-validation:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Validate JSON files
      run: |
        python -m json.tool projects.json > /dev/null
        python -m json.tool project_tags.json > /dev/null
        echo "‚úÖ JSON files are valid"
    
    - name: Check data consistency
      run: |
        python -c "
        import json
        with open('projects.json') as f:
            projects = json.load(f)['projects']
        with open('project_tags.json') as f:
            tags = json.load(f)
        
        # Check all projects have tags
        missing_tags = set(projects.keys()) - set(tags.keys())
        if missing_tags:
            print(f'‚ùå Projects without tags: {missing_tags}')
            exit(1)
        
        # Check all tagged projects exist
        orphan_tags = set(tags.keys()) - set(projects.keys())
        if orphan_tags:
            print(f'‚ùå Tags for non-existent projects: {orphan_tags}')
            exit(1)
            
        print('‚úÖ Data consistency check passed')
        "

  security-scan:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Run Trivy security scan
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  build-and-deploy:
    runs-on: ubuntu-latest
    needs: [lint-and-test, quality-check, data-validation]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Generate analytics reports
      run: |
        python analytics/report_generator.py all --format json
        python analytics/report_generator.py all --format markdown
    
    - name: Generate AI insights
      run: |
        python insights/ai_insights.py --generate-all
    
    - name: Build Docker image
      run: |
        docker build -t masterlist-app:${{ github.sha }} .
        docker tag masterlist-app:${{ github.sha }} masterlist-app:latest
    
    - name: Archive production artifacts
      uses: actions/upload-artifact@v3
      with:
        name: production-artifacts
        path: |
          data/reports/
          data/ai_insights.json
          qa_reports/

  performance-benchmark:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark
    
    - name: Run performance benchmarks
      run: |
        python -c "
        import time
        import json
        from tag_search import TagSearch
        from simple_tagger import SimpleTagger
        
        # Benchmark search performance
        searcher = TagSearch()
        start = time.time()
        results = searcher.search_by_tags(['ai-powered', 'high-revenue'])
        search_time = time.time() - start
        
        # Benchmark tagging performance
        tagger = SimpleTagger()
        start = time.time()
        with open('projects.json') as f:
            projects = json.load(f)['projects']
        for key in list(projects.keys())[:100]:
            tagger.auto_tag_project(key)
        tag_time = time.time() - start
        
        print(f'Search performance: {search_time:.3f}s')
        print(f'Tagging performance (100 projects): {tag_time:.3f}s')
        
        # Fail if performance degrades
        if search_time > 0.5:
            print('‚ùå Search performance degraded')
            exit(1)
        if tag_time > 5.0:
            print('‚ùå Tagging performance degraded')
            exit(1)
        
        print('‚úÖ Performance benchmarks passed')
        "

  documentation:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install documentation tools
      run: |
        pip install mkdocs mkdocs-material mkdocstrings[python]
    
    - name: Build documentation
      run: |
        # Would build MkDocs documentation here
        echo "üìö Documentation build step (placeholder)"
    
    - name: Check README completeness
      run: |
        python -c "
        import os
        required_sections = [
            '## Installation',
            '## Usage',
            '## Features',
            '## API',
            '## Contributing'
        ]
        
        with open('README.md') as f:
            content = f.read()
        
        missing = [s for s in required_sections if s not in content]
        if missing:
            print(f'‚ùå README missing sections: {missing}')
            exit(1)
        
        print('‚úÖ README check passed')
        "